 Factor Target Gene Prediction through
  Multi-Omics Datasets"
author: "A. Kapoor, D. Langreiter"
output:
  pdf_document: default
  html_document: default
---

# Introduction

**Aim:**  
The aim of this project is to apply classification techniques to predict novel transcription factor target genes, focusing on Sox2 and Nanog during embryonic stem cell (ESC) differentiation.

**Background:**  
Transcriptional regulation is a fundamental process in all living organisms, driven by transcription factors that control mRNA expression. These transcriptional networks are crucial in development, lineage specification, and cell fate decisions during early embryonic development ([Theunissen and Jaenisch, 2017](https://doi.org/10.1038/nrm.2017.15)). Recent advances in omics technologies allow for the profiling of genome-wide transcriptional and epigenetic events, providing a deeper understanding of these networks.

In this project, we utilize high-temporal-resolution multi-omics data of ESC differentiation ([Yang et al., 2019](https://doi.org/10.1016/j.cell.2019.02.035)) to predict novel substrates of Sox2 and Nanogâ€”two key transcription factors involved in maintaining pluripotency and guiding cell differentiation.

**Dataset Overview:**
- **Transcriptome:** Time-course mRNA profiles during ESC differentiation.
- **Proteome:** Time-course protein expression profiles during ESC differentiation.
- **Epigenome:** Time-course ESC differentation epigonme profiles of 6 histone marks.

We will develop and validate a classification model to predict novel transcription factor target genes, focusing on Sox2 and Nanog, using the provided multi-omics datasets.

# Data Preparation



## Load Required Libraries and Data

We start by loading the necessary R packages and the dataset `Final_Project_ESC.RData`, which contains the transcriptome, proteome, and epigenome data, along with a subset of known Sox2/Nanog target genes.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Load necessary packages and data
load("Final_Project_ESC.RData", verbose = TRUE)

#Install the calibrate Package
install.packages("calibrate")
library(calibrate)

suppressPackageStartupMessages({
    library(e1071)
    library(ggplot2)
    library(ROCR)
    library(dplyr)
    library(tibble)
    library(reshape2)
    library(kernlab)
    library(caret)
    library(randomForest)
    library(adabag)
    library(gbm)
    library(xgboost)
    library(pROC)
    library(doParallel)
})

```
#Describe and explore the Data set details
#Transcriptome

head(Transcriptome)
dim(Transcriptome)
colnames(Transcriptome)

# Load necessary libraries
library(ggplot2)
library(calibrate)

# PCA analysis on the correlation matrix of the transcriptome data
cor.mat <- cor(Transcriptome)
pca.mat <- prcomp(cor.mat)

# Plot the PCA
grp <- rownames(pca.mat$x)
grp.col <- rainbow(nrow(pca.mat$x))
names(grp.col) <- rownames(pca.mat$x)

# Generate PCA plot
plot(pca.mat$x[,1], pca.mat$x[,2], col=grp.col[grp], pch=19, cex=2, 
     xlab=paste0("PC1 (", round(summary(pca.mat)$importance[2,1]*100,1), "% variance)"),
     ylab=paste0("PC2 (", round(summary(pca.mat)$importance[2,2]*100,1), "% variance)"))

# Add sample labels to the plot
calibrate::textxy(pca.mat$x[,1], pca.mat$x[,2], labs=grp, cex=0.5)

#Proteome
cor.proteome <- cor(Proteome)
pca.proteome <- prcomp(cor.proteome)
summary(pca.proteome)$importance

# Using the previous correlation matrix and PCA results
cor.proteome <- cor(Proteome)
pca.proteome <- prcomp(cor.proteome)

# Get group labels and colors
grp <- rownames(pca.proteome$x)  # Set groups according to your data
grp.col <- rainbow(nrow(pca.proteome$x))
names(grp.col) <- rownames(pca.proteome$x)

# Plot the PCA
plot(pca.proteome$x[,1], pca.proteome$x[,2], col=grp.col[grp], pch=19, cex=2, 
     xlab=paste0("PC1 (", round(summary(pca.proteome)$importance[2,1]*100,1), "% variance)"),
     ylab=paste0("PC2 (", round(summary(pca.proteome)$importance[2,2]*100,1), "% variance)"))

#General PCA and Plotting Code for Epigenome Data
#h3k4me3
# PCA analysis on the correlation matrix of the H3K4me3 data
cor.h3k4me3 <- cor(H3K4me3)
pca.h3k4me3 <- prcomp(cor.h3k4me3)

# Get group labels and colors
grp <- rownames(pca.h3k4me3$x)
grp.col <- rainbow(nrow(pca.h3k4me3$x))
names(grp.col) <- rownames(pca.h3k4me3$x)

# Generate PCA plot for H3K4me3
plot(pca.h3k4me3$x[,1], pca.h3k4me3$x[,2], col=grp.col[grp], pch=19, cex=2, 
     xlab=paste0("PC1 (", round(summary(pca.h3k4me3)$importance[2,1]*100,1), "% variance)"),
     ylab=paste0("PC2 (", round(summary(pca.h3k4me3)$importance[2,2]*100,1), "% variance)"))

# Add sample labels to the plot
calibrate::textxy(pca.h3k4me3$x[,1], pca.h3k4me3$x[,2], labs=grp, cex=0.5)

#H3K27me3
# PCA analysis for H3K27me3 data
cor.h3k27me3 <- cor(H3K27me3)
pca.h3k27me3 <- prcomp(cor.h3k27me3)

# Update group labels and colors for H3K27ac
grp.h3k27ac <- rownames(pca.h3k27ac$x)
grp.col.h3k27ac <- rainbow(nrow(pca.h3k27ac$x))
names(grp.col.h3k27ac) <- rownames(pca.h3k27ac$x)

# Generate PCA plot for H3K27ac
plot(pca.h3k27ac$x[,1], pca.h3k27ac$x[,2], col=grp.col.h3k27ac[grp.h3k27ac], pch=19, cex=2, 
     xlab=paste0("PC1 (", round(summary(pca.h3k27ac)$importance[2,1]*100,1), "% variance)"),
     ylab=paste0("PC2 (", round(summary(pca.h3k27ac)$importance[2,2]*100,1), "% variance)"))

# Correctly label the samples for H3K27ac
calibrate::textxy(pca.h3k27ac$x[,1], pca.h3k27ac$x[,2], labs=grp.h3k27ac, cex=0.5)

#H3K4me1
# PCA analysis for H3K4me1 data
cor.h3k4me1 <- cor(H3K4me1)
pca.h3k4me1 <- prcomp(cor.h3k4me1)

# Define the group labels and colors specifically for H3K4me1 data
grp.h3k4me1 <- rownames(pca.h3k4me1$x)
grp.col.h3k4me1 <- rainbow(nrow(pca.h3k4me1$x))
names(grp.col.h3k4me1) <- rownames(pca.h3k4me1$x)

# Generate PCA plot for H3K4me1
plot(pca.h3k4me1$x[,1], pca.h3k4me1$x[,2], col=grp.col.h3k4me1[grp.h3k4me1], pch=19, cex=2, 
     xlab=paste0("PC1 (", round(summary(pca.h3k4me1)$importance[2,1]*100,1), "% variance)"),
     ylab=paste0("PC2 (", round(summary(pca.h3k4me1)$importance[2,2]*100,1), "% variance)"))

# Correctly label the samples for H3K4me1
calibrate::textxy(pca.h3k4me1$x[,1], pca.h3k4me1$x[,2], labs=grp.h3k4me1, cex=0.5)

#H3K9me2
# PCA analysis for H3K9me2 data
cor.h3k9me2 <- cor(H3K9me2)
pca.h3k9me2 <- prcomp(cor.h3k9me2)

# Define the group labels and colors specifically for H3K9me2 data
grp.h3k9me2 <- rownames(pca.h3k9me2$x)
grp.col.h3k9me2 <- rainbow(nrow(pca.h3k9me2$x))
names(grp.col.h3k9me2) <- rownames(pca.h3k9me2$x)

# Generate PCA plot for H3K9me2
plot(pca.h3k9me2$x[,1], pca.h3k9me2$x[,2], col=grp.col.h3k9me2[grp.h3k9me2], pch=19, cex=2, 
     xlab=paste0("PC1 (", round(summary(pca.h3k9me2)$importance[2,1]*100,1), "% variance)"),
     ylab=paste0("PC2 (", round(summary(pca.h3k9me2)$importance[2,2]*100,1), "% variance)"))

# Correctly label the samples for H3K9me2
calibrate::textxy(pca.h3k9me2$x[,1], pca.h3k9me2$x[,2], labs=grp.h3k9me2, cex=0.5)


#PolII
# PCA analysis for PolII data
cor.polii <- cor(PolII)
pca.polii <- prcomp(cor.polii)

# Define the group labels and colors specifically for PolII data
grp.polii <- rownames(pca.polii$x)
grp.col.polii <- rainbow(nrow(pca.polii$x))
names(grp.col.polii) <- rownames(pca.polii$x)

# Generate PCA plot for PolII
plot(pca.polii$x[,1], pca.polii$x[,2], col=grp.col.polii[grp.polii], pch=19, cex=2, 
     xlab=paste0("PC1 (", round(summary(pca.polii)$importance[2,1]*100,1), "% variance)"),
     ylab=paste0("PC2 (", round(summary(pca.polii)$importance[2,2]*100,1), "% variance)"))

# Correctly label the samples for PolII
calibrate::textxy(pca.polii$x[,1], pca.polii$x[,2], labs=grp.polii, cex=0.5)



## Filter and Combine Datasets
To ensure consistency across datasets, we filter each dataset to include only the common genes present in all omics layers. We then combine these filtered datasets into a single data frame for further analysis.

```{r}
# Ensure all data has the same set of genes
genes <- intersect(rownames(Transcriptome), rownames(Proteome))
genes <- intersect(genes, rownames(H3K4me3))
genes <- intersect(genes, rownames(H3K27me3))
genes <- intersect(genes, rownames(H3K27ac))
genes <- intersect(genes, rownames(H3K4me1))
genes <- intersect(genes, rownames(H3K9me2))
genes <- intersect(genes, rownames(PolII))
```

```{r}
# Filter each dataset for the common genes
Transcriptome_filter <- Transcriptome[genes, ]
Proteome_filter <- Proteome[genes, ]
H3K4me3_filter <- H3K4me3[genes, ]
H3K27me3_filter <- H3K27me3[genes, ]
H3K27ac_filter <- H3K27ac[genes, ]
H3K4me1_filter <- H3K4me1[genes, ]
H3K9me2_filter <- H3K9me2[genes, ]
PolII_filter <- PolII[genes, ]
```

```{r}
# Rename columns to avoid conflicts
colnames(Transcriptome_filter) <- paste("T_", colnames(Transcriptome_filter), sep = "")
colnames(Proteome_filter) <- paste("P_", colnames(Proteome_filter), sep = "")
colnames(H3K4me3_filter) <- paste("H3K4me3_", colnames(H3K4me3_filter), sep = "")
colnames(H3K27me3_filter) <- paste("H3K27me3_", colnames(H3K27me3_filter), sep = "")
colnames(H3K27ac_filter) <- paste("H3K27ac_", colnames(H3K27ac_filter), sep = "")
colnames(H3K4me1_filter) <- paste("H3K4me1_", colnames(H3K4me1_filter), sep = "")
colnames(H3K9me2_filter) <- paste("H3K9me2_", colnames(H3K9me2_filter), sep = "")
colnames(PolII_filter) <- paste("PolII_", colnames(PolII_filter), sep = "")

# Combine the datasets
combined_data <- cbind(
  Transcriptome_filter,
  Proteome_filter,
  H3K4me3_filter,
  H3K27me3_filter,
  H3K27ac_filter,
  H3K4me1_filter,
  H3K9me2_filter,
  PolII_filter
)

# Add the labels
label <- ifelse(genes %in% OSN_target_genes_subset, "OSN", "Other")
combined_data <- data.frame(combined_data)
combined_data$label <- factor(label)
```

```{r}
# Check the initial label distribution
print(table(combined_data$label))
```

## Data Splitting and Balancing

The dataset is split into training (90%) and testing (10%) sets. The label column is reassigned to the test set to ensure that it is included correctly.

```{r}
# Split the dataset into training (90%) and testing (10%) sets
set.seed(123)
train_index <- createDataPartition(combined_data$label, p = 0.9, list = FALSE)

train_data <- combined_data[train_index, ]
test_data <- combined_data[-train_index, ]

# Reassign the label column to test_data
test_data$label <- combined_data[-train_index, "label"]

# Check the distribution of labels in the training and test sets
print("Training set label distribution:")
print(table(train_data$label))

print("Test set label distribution:")
print(table(test_data$label))

```

## Balancing the Training Data
Since the dataset is imbalanced, downsampling is used to create a balanced training dataset. This ensures that both classes (OSN and Other) are equally represented, improving the robustness of the classification model.

```{r}
# Balance the training data using downsampling
set.seed(123)
downsampled_train_data <- downSample(x = train_data[, -ncol(train_data)], 
                                     y = train_data$label, 
                                     yname = "label")

# Check the balanced label distribution
print("Balanced training set label distribution:")
print(table(downsampled_train_data$label))
```

```{r}
# Final check of training dataset dimensions
print(dim(downsampled_train_data))

```

# Model Training
Train SVM and Random Forest Models
We train two machine learning models, SVM and Random Forest, using the balanced training dataset.

```{r}
# Train an SVM model on the downsampled training data
set.seed(123)
svm_model <- svm(label ~ ., data = downsampled_train_data, kernel = "radial", probability = TRUE)

# Train a Random Forest model on the downsampled training data
set.seed(123)
rf_model <- randomForest(label ~ ., data = downsampled_train_data, ntree = 500)

```

## Bagging w/ Bagged Trees

```{r}

bagged_trees <- train(
  label ~ .,
  data = downsampled_train_data,
  method = "treebag",
  trControl = trainControl(method = "cv", number = 5),
  tuneLength = 5
)
print(bagged_trees)

```

## GBM w/ Hyperparam Tuning and xgboost (using parallel processing)

```{r}

tune_grid_xgb <- expand.grid(
  nrounds = c(100, 200),
  max_depth = c(3, 6),
  eta = c(0.1, 0.3),
  gamma = c(0, 0.1),
  colsample_bytree = c(0.5, 1),
  min_child_weight = c(1, 10),
  subsample = c(0.5, 1)
)

cl <- makeCluster(detectCores())
registerDoParallel(cl)

train_control <- trainControl(
  method = "cv",
  number = 3,
  savePredictions = "final",
  verboseIter = TRUE,
  allowParallel = TRUE
)

xgb_model_tuned <- train(
  label ~ .,
  data = downsampled_train_data,
  method = "xgbTree",
  trControl = train_control,
  tuneGrid = tune_grid_xgb,
  metric = "Accuracy"  # Performance Metric
)
print(xgb_model_tuned)

# Printing the best model's details
print(xgb_model_tuned$bestTune)

# Plotting model performance
plot(xgb_model_tuned)


```

# Model Evaluation
Predictions and Confusion Matrix
We use the trained models to make predictions on the test set and evaluate their performance using confusion matrices.

```{r}
# Ensure column names in the test set match the training data
colnames(test_data) <- colnames(downsampled_train_data)[1:(ncol(downsampled_train_data) - 1)]  # Exclude the label column

# Check if the label column is present and correctly populated
if ("label" %in% colnames(combined_data) && length(combined_data[-train_index, "label"]) == nrow(test_data)) {
    # Assign the label to test_data
    test_data$label <- combined_data[-train_index, "label"]
} else {
    stop("The label vector is empty or has a different length than expected. Check the data preparation steps.")
}

# Ensure the label is a factor with the correct levels
test_data$label <- factor(test_data$label, levels = c("OSN", "Other"))

# SVM Predictions on the test set
svm_test_pred <- predict(svm_model, newdata = test_data[, -ncol(test_data)], probability = TRUE)
svm_test_prob <- attr(svm_test_pred, "probabilities")[, "OSN"]

# Random Forest Predictions on the test set
rf_test_pred <- predict(rf_model, newdata = test_data[, -ncol(test_data)], type = "prob")[, "OSN"]

# SVM Confusion Matrix on the test set
svm_test_conf_matrix <- table(Predicted = ifelse(svm_test_prob > 0.5, "OSN", "Other"), Actual = test_data$label)
print("SVM Test Confusion Matrix:")
print(svm_test_conf_matrix)

# Random Forest Confusion Matrix on the test set
rf_test_conf_matrix <- table(Predicted = ifelse(rf_test_pred > 0.5, "OSN", "Other"), Actual = test_data$label)
print("Random Forest Test Confusion Matrix:")
print(rf_test_conf_matrix)

```

## ROC Curve and AUC
To further assess model performance, we plot the ROC curves and calculate the AUC for both the SVM and Random Forest models.

```{r}
# Evaluate the models on the test set (AUC and ROC)
svm_test_roc <- roc(test_data$label, svm_test_prob)
plot(svm_test_roc, main = "SVM ROC Curve")
print(paste("Final SVM Test AUC:", auc(svm_test_roc)))

rf_test_roc <- roc(test_data$label, rf_test_pred)
plot(rf_test_roc, main = "Random Forest ROC Curve")
print(paste("Final Random Forest Test AUC:", auc(rf_test_roc)))

```

# Future Directions:

**Model Improvement:**  
Further hyperparameter tuning using automated methods like grid search or random search could refine the model's accuracy. Additionally, exploring ensemble methods that combine predictions from several models might yield better results.

**Data Expansion:**  
Incorporating additional omics layers, such as metabolomics or additional transcription factor binding profiles, could help to improve the model's predictive power and generalisability.

**Integration with Clinical Data:**  
Linking omics profiles with clinical outcomes could also be explored to improve the translational impact of the research.
